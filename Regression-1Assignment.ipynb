{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aff3316-8b27-4afe-8091-fd1a13931309",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an\n",
    "example of each.\n",
    "\n",
    "Ans. \n",
    "\n",
    "Simple linear regression:\n",
    "    \n",
    "- Definition: Models relationship between one independent variable and one dependent variable. It has 1 independenet variable \n",
    "- It has 1 independenet variable. \n",
    "- Example - Predicting weight based on height\n",
    "\n",
    "Multiple linear regression:\n",
    "\n",
    "- Definition: Models relationship between two or more independent variables and one dependent variable.\n",
    "- It has 2 or more independent variable.\n",
    "- Example - Predicting weight based on height, age, and gender."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b2878-0b1a-420d-8305-bbc5a7109fb5",
   "metadata": {},
   "source": [
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in\n",
    "a given dataset?\n",
    "\n",
    "Ans. Mainly there are 7 assumptions taken while using Linear Regression:\n",
    "\n",
    "- Linear Model\n",
    "- Check: Plot residuals vs. predicted values; use scatter plots.\n",
    "- No Multicolinearlity in the data\n",
    "- Check: Calculate Variance Inflation Factor (VIF); check correlation matrix.\n",
    "- Homoscedasticity of Residuals or Equal Variances\n",
    "- Check: Plot residuals vs. fitted values; use Breusch-Pagan test.\n",
    "- Independence: Residuals are independent.\n",
    "- Check: Use Durbin-Watson test (for time series) or plot residuals over time.\n",
    "- Number of observations Greater than the number of predictors\n",
    "- Each observation is unique\n",
    "- Predictors are distributed Normally"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8b01cc-d0b1-4f04-9841-1932f2a872d2",
   "metadata": {},
   "source": [
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using\n",
    "a real-world scenario.\n",
    "\n",
    "Ans. Interpretation\n",
    "Intercept (β0): The value of the dependent variable when the independent variable is zero.\n",
    "\n",
    "Slope (β1): The change in the dependent variable for a one-unit change in the independent variable.\n",
    "\n",
    "To interpret the slope of the line, identify the variables in the situation. Since slope is change in y divided by change in x, divide the y-variable by the x-variable to get the units for the slope. \n",
    "\n",
    "Interpreting the Intercept in Simple Linear Regression:\n",
    "\n",
    "Example: Suppose we’d like to fit a simple linear regression model using hours studied as a predictor variable and exam score as the response variable.\n",
    "We collect this data for 50 students in a certain college course and fit the following regression model:\n",
    "\n",
    "Exam score = 65.4 + 2.67(hours)\n",
    "\n",
    "The value for the intercept term in this model is 65.4. This means the average exam score is 65.4 when the number of hours studied is equal to zero.\n",
    "\n",
    "This makes sense to interpret since it’s plausible for a student to study for zero hours in preparation for an exam.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c37c9de-ae03-431b-b47e-81d3d6b85873",
   "metadata": {},
   "source": [
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "\n",
    "Ans. Gradient descent is an optimization algorithm used to minimize the cost function in machine learning models. It iteratively adjusts the parameters of the model to reduce the difference between the predicted and actual values.\n",
    "\n",
    "It trains machine learning models by minimizing errors between predicted and actual results. Training data helps these models learn over time, and the cost function within gradient descent specifically acts as a barometer, gauging its accuracy with each iteration of parameter updates.\n",
    "\n",
    "In machine learning, gradient descent is used to:\n",
    "\n",
    "Optimize Parameters: \n",
    "Adjust model parameters (weights and biases) to minimize the cost function (e.g., prediction error).\n",
    "\n",
    "Process:\n",
    "\n",
    " - Initialize: Start with initial parameter values.\n",
    "- Compute: Calculate gradients of the cost function.\n",
    "- Update: Adjust parameters to reduce the cost.\n",
    "- Iterate: Repeat until the cost function is minimized.\n",
    "\n",
    "Variants:\n",
    "\n",
    "- Batch Gradient Descent: Uses the entire dataset.\n",
    "- Stochastic Gradient Descent (SGD): Uses one data point at a time.\n",
    "- Mini-Batch Gradient Descent: Uses a subset of the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c78f14-4bbd-4a2f-bf6d-8faf3973c13a",
   "metadata": {},
   "source": [
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "\n",
    "Ans. Multiple linear regression models the relationship between one dependent variable and two or more independent variables. It predicts the dependent variable based on the combined influence of multiple predictors.\n",
    "\n",
    "Simple Linear Regression Involves one independent variable while Multiple Linear Regression Involves two or more independent variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0176b-374a-454e-9f6e-b49042e2a495",
   "metadata": {},
   "source": [
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and\n",
    "address this issue?\n",
    "\n",
    "Ans. Multicollinearity occurs when independent variables in a multiple linear regression model are highly correlated with each other. This can make it difficult to isolate the individual effect of each predictor on the dependent variable and can lead to unreliable estimates of regression coefficients.\n",
    "\n",
    "Detection\n",
    "\n",
    "Variance Inflation Factor (VIF):\n",
    "\n",
    "Calculation: Compute VIF for each independent variable.\n",
    "Interpretation: A VIF value greater than 10 suggests high multicollinearity.\n",
    "\n",
    "Correlation Matrix:\n",
    "\n",
    "Calculation: Check the pairwise correlations between independent variables.\n",
    "Interpretation: High correlations (close to ±1) indicate multicollinearity.\n",
    "\n",
    "Condition Index:\n",
    "\n",
    "Calculation: Use matrix decomposition to compute condition indices.\n",
    "Interpretation: A condition index above 30 suggests significant multicollinearity.\n",
    "\n",
    "Addressing Multicollinearity\n",
    "\n",
    "Remove Variables:\n",
    "\n",
    "Action: Remove highly correlated predictors from the model.\n",
    "\n",
    "Combine Variables:\n",
    "\n",
    "Action: Combine correlated variables into a single predictor (e.g., principal component analysis).\n",
    "\n",
    "Regularization:\n",
    "\n",
    "Action: Use techniques like Ridge or Lasso regression to penalize large coefficients and reduce multicollinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21db8789-04f2-4db8-88be-b35c7bcb3cf3",
   "metadata": {},
   "source": [
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "\n",
    "Ans. Polynomial regression is a type of regression that models the relationship between the independent variable and the dependent variable as an n-th degree polynomial. It allows for more complex, non-linear relationships.\n",
    "\n",
    "Linear Regression Models a straight-line relationship between the independent variable and the dependent variable While Polynomial Regression Models a curved relationship by including higher-degree terms of the independent variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c2988ba-d719-4f66-b4dd-f16abb856df7",
   "metadata": {},
   "source": [
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear\n",
    "regression? In what situations would you prefer to use polynomial regression?\n",
    "\n",
    "Ans. Advanatage:\n",
    "- Captures Non-Linearity: Can model complex, non-linear relationships between variables.\n",
    "- Flexible Fit: Provides a better fit for data with curves or patterns that a linear model cannot capture.\n",
    "\n",
    "Disadvantage:\n",
    "- Overfitting: Higher-degree polynomials can lead to overfitting, where the model captures noise instead of the underlying pattern.\n",
    "- Complexity: More complex models can be harder to interpret and require more computational resources\n",
    "\n",
    "When to Use Polynomial Regression\n",
    "\n",
    "- Non-Linear Data: When the relationship between variables is curved or non-linear.\n",
    "- Complex Patterns: When data shows patterns that a linear model cannot fit well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe6d153d-ebc5-4542-8ece-cdb747371ceb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
